# Detec√ß√£o de Fraudes em Transa√ß√µes Financeiras em Tempo Real

![Badge](https://img.shields.io/badge/status-em%20conclu√≠dp-yellow)

<p align ='center'>
    <img width="1000" src="projeto.jpg">
</p>


Este projeto tem como objetivo detectar transa√ß√µes fraudulentas em tempo real utilizando um pipeline de dados que envolve PostgreSQL, Debezium, Apache Kafka, PyCaret (Machine Learning), Elasticsearch e Kibana.

## üìã Tabela de Conte√∫dos

- [Vis√£o Geral](#vis√£o-geral)
- [Funcionalidades](#funcionalidades)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Etapas do Projeto](#etapas-do-projeto)
- [Instala√ß√£o e Configura√ß√£o](#instala√ß√£o-e-configura√ß√£o)
- [Uso](#uso)


## üåü Vis√£o Geral

O sistema √© composto por um pipeline de dados que:
1. Captura mudan√ßas em um banco de dados PostgreSQL usando **Debezium** (Change Data Capture - CDC).
2. Envia os dados para um t√≥pico no **Apache Kafka**.
3. Consome os dados com um modelo de Machine Learning treinado com **PyCaret** para prever fraudes.
4. Envia as previs√µes (transa√ß√µes aprovadas ou fraudulentas) para outro t√≥pico no Kafka.
5. Armazena os dados no **Elasticsearch** e visualiza os resultados em um dashboard no **Kibana**.

## ‚ú® Funcionalidades

- **Detec√ß√£o em Tempo Real**: Identifica transa√ß√µes fraudulentas instantaneamente.
- **Pipeline de Dados Integrado**: Utiliza tecnologias modernas para processamento de dados em tempo real.
- **Dashboard de Monitoramento**: Visualiza√ß√µes em tempo real das transa√ß√µes aprovadas e fraudulentas.

## üõ† Tecnologias Utilizadas

- **PostgreSQL**: Banco de dados transacional.
- **Debezium**: Captura de mudan√ßas no banco de dados (CDC).
- **Apache Kafka**: Sistema de mensageria para streaming de dados.
- **PyCaret**: Biblioteca de Machine Learning para treinamento e previs√£o.
- **Elasticsearch**: Armazenamento e indexa√ß√£o de dados.
- **Kibana**: Visualiza√ß√£o e monitoramento dos dados.
- **Python**: Linguagem principal para scripts e modelo de Machine Learning.

## üöÄ Etapas do Projeto

1. **Cria√ß√£o do Modelo de Previs√£o**:
   - Utilizar o PyCaret para treinar um modelo de Machine Learning com dados hist√≥ricos de transa√ß√µes.
   - Exportar o modelo treinado para uso no pipeline.

2. **Configura√ß√£o do PostgreSQL e Carga de Dados**:
   - Configurar o banco de dados PostgreSQL.
   - Criar um script para carregar dados de transa√ß√µes no banco.

3. **Configura√ß√£o do Debezium e Kafka**:
   - Configurar o Debezium para capturar mudan√ßas no PostgreSQL.
   - Enviar os dados capturados para um t√≥pico no Kafka.

4. **Integra√ß√£o do Modelo com Kafka**:
   - Consumir os dados do t√≥pico Kafka com o modelo de Machine Learning.
   - Enviar as previs√µes (aprovado/fraudulento) para outro t√≥pico no Kafka.

5. **Configura√ß√£o do Elasticsearch e Kibana**:
   - Configurar o Elasticsearch para armazenar as previs√µes.
   - Criar um dashboard no Kibana para visualizar as transa√ß√µes aprovadas e fraudulentas.

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

- Docker e Docker Compose (para facilitar a configura√ß√£o dos servi√ßos).
- Python 3.8+.

## üöÄ Uso
Ap√≥s a configura√ß√£o, o sistema estar√° pronto para:

Capturar transa√ß√µes em tempo real.

Classificar as transa√ß√µes como aprovadas ou fraudulentas.

Visualizar os resultados no Kibana.